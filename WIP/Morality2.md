---
layout: post
title:  "Morality, Relative Intelligence, and Heuristics"
date:   2018-01-15 23:35:00
categories: [ai, morality]
---
In a world without bounds on time and computation, morality is trivial. Take all of the consequences of an action and compare them to the consequences of all other actions in n-dimensional space. Once you've arrived at a set of morally good actions, pick one and you're behaving morally. 

It is only in our bounded world that this becomes complicated. Human intelligence, unlike the universe that it interacts with, is finite. Consequentialism is not a useful approach to creatures who can't predict consequences because there are too many
 
Our capacity for morality 

Moral significance is tied inexorably to intelligence, and specifically to predictive intelligence- multiply the negative or positive intent of an entity by the degree to which it can see the consequences of its actions




Morality is by nature consequentialist. The moral value of an action can only be determined by the moral value of its outcome. But outcomes are complex and infinite, while our brains are less complex and finite. Our brains are bound by response times in a universe where inaction also has consequences. Moral value requires infinite computational time and taking that time to determine whether an action is good or evil 